{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] Logging into Synapse via apikeys will be deprecated by early 2024.  If you've used `rememberMe=True` in the past, you may also be getting this message, please delete your ~/.synapseCache/.session file. This message will disappear if you use a Synapse Personal Access Token to login.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome, Jineta Banerjee!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import synapseclient\n",
    "syn = synapseclient.Synapse()\n",
    "syn.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from synapseclient import Activity\n",
    "from synapseclient import Entity, Project, Folder, File, Link\n",
    "from synapseclient import Evaluation, Submission, SubmissionStatus\n",
    "from synapseclient import Wiki\n",
    "import synapseutils\n",
    "from re import search\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make dataset with all cram and crai files\n",
    "\n",
    "syn52357115 contains all aligned files for all samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a dataset by recursively adding folders:\n",
    "dataset = syn.get(\"syn52357115\") #pull in empty dataset entity\n",
    "\n",
    "# Add a list of Folders, overwriting any existing files in the dataset\n",
    "dataset.add_folders([\"syn51832064\", \n",
    "\"syn51833559\",\n",
    "\"syn51833711\",\n",
    "\"syn51834988\",\n",
    "\"syn51835488\",\n",
    "\"syn51835546\",\n",
    "\"syn52601592\", #jh-batch1-missed-samples\n",
    "\"syn52593527\", #mixed-kit-samples\n",
    "\"syn52654065\", #wu-batches-corrected-samples\n",
    "\"syn52593659\" #wu-batches-missed-samples\n",
    "], force=True)\n",
    "\n",
    "dataset = syn.store(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make dataset with strelka and mutect2 vcf files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a dataset by recursively adding folders:\n",
    "dataset = syn.get(\"syn52656598\") #pull in empty dataset entity\n",
    "\n",
    "# Add a list of Folders, overwriting any existing files in the dataset\n",
    "dataset.add_folders([\"syn52601661\", #jh-batch1-missed-samples \n",
    "\"syn51832454\", #jh-batch1\n",
    "\"syn52593603\", #mixed-kit-samples\n",
    "\"syn52654119\", #wu-batches-corrected-samples\n",
    "\"syn52593771\", #wu-batches-missed-samples\n",
    "\"syn51833586\", #wu-batch1-batch2\n",
    "\"syn51834214\", #wubatch1-new\n",
    "\"syn51835402\" #wu-batch2-new\n",
    "#\"syn51835521\", #wu-pdx-batch1-new\n",
    "#\"syn51835594\" #wu-pdx-batch2-new\n",
    "], force=True)\n",
    "\n",
    "dataset = syn.store(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "select only vcf.gz and vcf.gz.tbi files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = syn.get(\"syn52656598\")\n",
    "df2 = pd.DataFrame(columns=[\"files\", \"synid\"])\n",
    "for f in dataset.datasetItems:\n",
    "   f_id = f.get('entityId')\n",
    "   filename = syn.get(f_id, downloadFile=False).get('name')\n",
    "   df = pd.DataFrame(filename.split(\"\\n\"), columns = ['files'])\n",
    "   df['synid'] = f_id\n",
    "   df2 = df2.append(df)   \n",
    "\n",
    "selected_files = df2[df2[\"files\"].str.endswith('mutect2.filtered.vcf.gz') | \n",
    "                     df2[\"files\"].str.endswith('mutect2.filtered.vcf.gz.tbi') | \n",
    "                     df2[\"files\"].str.endswith('strelka.somatic_indels.vcf.gz') |\n",
    "                     df2[\"files\"].str.endswith('strelka.somatic_indels.vcf.gz.tbi') |\n",
    "                     df2[\"files\"].str.endswith('strelka.somatic_snvs.vcf.gz') |\n",
    "                     df2[\"files\"].str.endswith('strelka.somatic_snvs.vcf.gz.tbi')]\n",
    "\n",
    "unwanted_files = df2[~df2.synid.isin(selected_files.synid)]\n",
    "\n",
    "# remove specific files from the dataset\n",
    "for i in range(len(unwanted_files.synid)):\n",
    "    #print(i)\n",
    "    #print(unwanted_files.synid.iloc[i])\n",
    "    dataset.remove_item(unwanted_files.synid.iloc[i])\n",
    "\n",
    "dataset = syn.store(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternate method to preselect items to add to dataset (not recommended if the number of items in parent folder is too many)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = synapseutils.sync.syncFromSynapse(syn, \"syn51831408\", downloadFile=False)\n",
    "files_df = pd.DataFrame(files)\n",
    "files_df = files_df[[\"id\", 'name', 'versionNumber']]\n",
    "\n",
    "selected_files = files_df[files_df[\"name\"].str.endswith('mutect2.filtered.vcf.gz') | \n",
    "                     files_df[\"name\"].str.endswith('mutect2.filtered.vcf.gz.tbi') | \n",
    "                     files_df[\"name\"].str.endswith('strelka.somatic_indels.vcf.gz') |\n",
    "                     files_df[\"name\"].str.endswith('strelka.somatic_indels.vcf.gz.tbi') |\n",
    "                     files_df[\"name\"].str.endswith('strelka.somatic_snvs.vcf.gz') |\n",
    "                     files_df[\"name\"].str.endswith('strelka.somatic_snvs.vcf.gz.tbi')]\n",
    "\n",
    "items = selected_files[[\"id\", \"versionNumber\"]]\n",
    "items.columns = [\"entityId\", \"versionNumber\"]\n",
    "items = items.to_dict('records')\n",
    "\n",
    "dataset = synapseclient.Dataset(\n",
    "    name=\"NF-OSI-processed-WES-strelka-mutect2-vcfs-2023\",\n",
    "    parent=\"syn4939902\",\n",
    "    dataset_items = items\n",
    ")\n",
    "dataset = syn.store(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download items to local machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downloading items from a dataset:\n",
    "\n",
    "df = syn.get(\"syn52656598\")\n",
    "for f in df.datasetItems:\n",
    "   f_id = f.get('entityId')\n",
    "   filename = syn.get(f_id, downloadFile=False, downloadLocation = \"add path here\")\n",
    "   print(f_id)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a1520fff7cfd7087e7c633877a43a7a6055f5cdda6c3f509280dc0c9a2a1b1a0"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('reticulate_conda')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
